Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import onnx.  No module named 'onnx'
Using CPU...
model arch:
mlp top arch 3 layers, with input to output dimensions:
[8 4 2 1]
# of interactions
8
mlp bot arch 2 layers, with input to output dimensions:
[4 3 2]
# of features (sparse and dense)
4
dense feature size
4
sparse feature size
2
# of embeddings (= # of sparse features) 3, with dimensions 2x:
[4 3 2]
data (inputs and targets):
mini-batch: 0
tensor([[0.6965, 0.2861, 0.2269, 0.5513],
        [0.7195, 0.4231, 0.9808, 0.6848]])
tensor([[1, 2],
        [1, 1],
        [1, 1]], dtype=torch.int32)
[tensor([1, 0, 1]), tensor([0, 1]), tensor([1, 0])]
tensor([[0.3618],
        [0.2283]])
mini-batch: 1
tensor([[0.2937, 0.6310, 0.0921, 0.4337],
        [0.4309, 0.4937, 0.4258, 0.3123]])
tensor([[1, 2],
        [1, 2],
        [1, 1]], dtype=torch.int32)
[tensor([3, 0, 2]), tensor([1, 1, 2]), tensor([1, 1])]
tensor([[0.6031],
        [0.5451]])
mini-batch: 2
tensor([[0.3428, 0.3041, 0.4170, 0.6813]])
tensor([[1],
        [2],
        [1]], dtype=torch.int32)
[tensor([2]), tensor([0, 2]), tensor([0])]
tensor([[0.5725]])
initial parameters (weights and bias):
[[-0.40429  0.38533]
 [ 0.12725  0.22342]
 [-0.48387  0.09443]
 [ 0.05679 -0.34104]]
[[-0.4006   0.22578]
 [-0.20927  0.22167]
 [ 0.0628  -0.12823]]
[[ 0.60123  0.48319]
 [-0.20167 -0.64546]]
[[-0.44767 -0.85842  0.67095 -0.36822]
 [ 0.88782  0.43152 -0.16825 -0.58044]
 [-0.39152 -0.64812  1.11561  0.0879 ]]
[ 0.66407 -0.73171  0.10452]
[[ 0.74495 -0.21188  0.65213]
 [-0.68594 -0.86234  0.23995]]
[-0.26812  0.454  ]
[[-0.80747  0.29078  1.06075 -0.01005  0.01394  0.0733  -0.76015  0.17397]
 [-0.65541 -0.1746   0.5074  -0.30015  0.20463  0.41345  0.1138  -0.55969]
 [-0.13573  0.79993 -0.82672 -0.11259 -0.2254   0.04929  0.30546  0.65675]
 [-0.11032  0.33164  0.20402  0.19365 -0.23022 -0.40715 -0.44909 -0.30881]]
[ 0.16084  0.38047  0.16173 -0.27448]
[[ 1.04268  0.87692 -0.20438 -0.47541]
 [ 0.07518  0.73168  0.19212  0.32132]]
[-0.14996  0.32263]
[[ 1.26112 -0.19569]]
[0.14331]
time/loss/accuracy (if enabled):
Finished training it 1/3 of epoch 0, -1.00 ms/it, loss 0.082442
Finished training it 2/3 of epoch 0, -1.00 ms/it, loss 0.013636
Finished training it 3/3 of epoch 0, -1.00 ms/it, loss 0.001983
Finished training it 1/3 of epoch 1, -1.00 ms/it, loss 0.068620
Finished training it 2/3 of epoch 1, -1.00 ms/it, loss 0.011475
Finished training it 3/3 of epoch 1, -1.00 ms/it, loss 0.000386
Finished training it 1/3 of epoch 2, -1.00 ms/it, loss 0.062587
Finished training it 2/3 of epoch 2, -1.00 ms/it, loss 0.010087
Finished training it 3/3 of epoch 2, -1.00 ms/it, loss 0.000010
updated parameters (weights and bias):
[[-0.40723  0.3733 ]
 [ 0.12615  0.19778]
 [-0.48393  0.08357]
 [ 0.05687 -0.34108]]
[[-0.40114  0.22456]
 [-0.20453  0.22049]
 [ 0.06539 -0.13002]]
[[ 0.59704  0.48359]
 [-0.20937 -0.64465]]
[[-0.44601 -0.85545  0.6761  -0.36419]
 [ 0.88782  0.43152 -0.16825 -0.58044]
 [-0.38923 -0.64658  1.11867  0.09177]]
[ 0.67066 -0.73171  0.10961]
[[ 0.74808 -0.21188  0.65629]
 [-0.68698 -0.86234  0.23867]]
[-0.25809  0.4558 ]
[[-0.80809  0.27681  1.05741 -0.0124   0.01164  0.08042 -0.75418  0.17639]
 [-0.65817 -0.1872   0.50465 -0.30191  0.20209  0.41675  0.11725 -0.55769]
 [-0.13426  0.80406 -0.82566 -0.11213 -0.22429  0.04897  0.30432  0.65616]
 [-0.11032  0.33649  0.20506  0.19475 -0.23025 -0.41029 -0.45104 -0.30957]]
[ 0.12402  0.34729  0.17287 -0.26259]
[[ 1.02711  0.86462 -0.2171  -0.47772]
 [ 0.07775  0.73422  0.19408  0.3217 ]]
[-0.19524  0.33122]
[[ 1.24878 -0.22178]]
[0.10141]
